# -*- coding: utf-8 -*-
"""EXERCISE 3 1934041

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UyT0BHD-z4INPc7MLOdsfRePG0E8cWEa

# **IMPORTING THE LIBRARIES**
"""

from sklearn import datasets
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier 
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn import model_selection 
import numpy
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV

"""# **LOADING THE DATASET**"""

iris = datasets.load_iris()

print(iris)

dt = pd.DataFrame({'sepal length':iris.data[:,0],'sepalwidth':iris.data[:,1],'petal length':iris.data[:,2], 'petalwidth':iris.data[:,3],'species':iris.target})

dt

"""# CHECKING FOR NULL VALUES"""

dt.isnull().sum()

X = dt.drop('species', axis=1)
y = dt['species']

"""# KFOLD INITIATION"""

kfold = model_selection.KFold(n_splits=10)

"""# TRAIN TEST VALUE SPLIT"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)

"""# SCALING THE VALUES"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# **DECISION TREE CLASSIFIER**

# HYPERPARAMTER TUNING DECISION TREE CLASSIFIER
"""

dt=DecisionTreeClassifier()

params = {
    'max_depth': [2, 3, 5, 10, 20],
    'min_samples_leaf': [5, 10, 20, 50, 100],
    'criterion': ["gini", "entropy"]
}

# Instantiate the grid search model
grid_search = GridSearchCV(estimator=dt, 
                           param_grid=params, 
                           cv=4, n_jobs=-1, verbose=1, scoring = "accuracy")

grid_search.fit(X_train, y_train)

grid_search.best_estimator_

"""# TEST AND TRAIN SC0RE AFTER FITTING THE MODEL"""

classifier = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=2, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=5, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=None, splitter='best')
classifier.fit(X_train, y_train)
print(classifier.score(X_train,y_train))
y_pred = classifier.predict(X_test)

classifier.fit(X_test,y_test)

classifier.score(X_test,y_test)

"""# CLASSIFICATION REPORT OF DTC"""

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""**CROSS VALIDATION SCORE OF DTC**"""

results = cross_val_score(classifier,X,y,cv=kfold)
print(results.mean())

"""# **ADABOOST CLASSFIER**

# TRAIN AND TEST ACORE AFER FITTING THE MODEL
"""

adb=AdaBoostClassifier(classifier ,n_estimators=5,learning_rate=0.1,random_state=23)
adb.fit(X_train, y_train)
print(adb.score(X_train,y_train))
y_pred1 = adb.predict(X_test)

adb.fit(X_test,y_test)

adb.score(X_test,y_test)

"""# CLASSIFICATION REPORT OF ADABOOST"""

print(confusion_matrix(y_test, y_pred1))
print(classification_report(y_test, y_pred1))

"""**CROSS VALIDATION SCORE OF ADABOOST CLASSFIER**"""

model1 = AdaBoostClassifier(n_estimators=5,random_state=23)
results1 = cross_val_score(model1,X,y,cv=kfold)
print(results1.mean())

"""# **GRADIENT BOOSTING CLASSIFIER**

# TRAIN AND TEST SCORE AFTER FITTING THE MODEL
"""

gb = GradientBoostingClassifier(n_estimators=5, learning_rate=1, max_depth=2,random_state=23)
gb.fit(X_train, y_train)
print(gb.score(X_train,y_train))
y_pred2 = gb.predict(X_test)

gb.fit(X_test,y_test)

gb.score(X_test,y_test)

"""# CLASSIFICATION REPORT OF GRADIENT BOOSTING CLASSFIER"""

print(confusion_matrix(y_test, y_pred2))
print(classification_report(y_test, y_pred2))

"""**CROSS VALIDATION SCORE OF GRADIENT BOOSTING CLASSFIER**"""

model2 = GradientBoostingClassifier(n_estimators=5,random_state=23)
results2 = cross_val_score(model2,X,y,cv=kfold)
print(results2.mean())